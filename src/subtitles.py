from faster_whisper.transcribe import Segment, Word
import re
from transcribe import transcribe, TranscribeOptions
from filters import compile_filters, filter_transcription
import ffmpeg
import os, pathlib
from dataclasses import dataclass

@dataclass
class Subtitle:
  start: float
  end: float
  words: list[Word]

def layout_subtitles(segments: list[Segment]) -> list[Subtitle]:
  """Transforms a list of transcription segments into a list of subtitles."""
  # Conventions to follow: https://engagemedia.org/help/best-practices-for-online-subtitling/
  # - Max = 2 lines
  # - In general, appear and disappear with timing of spoken text.
  # - Minimum time = max(1.5 seconds, long enough to read), unless next line needs to appear sooner.
  # - If a line is repeated, insert a blank gap between the repeats.
  # - Separate subtitle for each sentence, except for very short sentences.
  # - Prefer line break on punctuation.
  # More conventions: https://diposit.ub.edu/dspace/bitstream/2445/128428/1/subtitling%20and%20captioning.pdf
  # - 40 characters per line
  # - >=1.5, <=6 seconds per subtitle
  # - 0.125 second gap between subtitles
  words = [word for segment in segments for word in segment.words]
  sentences = _group_sentences(words)
  subtitles = []
  subtitle_char_count = 0
  subtitle_words = []
  for sentence in sentences:
    if len(subtitle_words) > 0:
      start = subtitle_words[0].start
      end = max(start + 1.5, subtitle_words[-1].end)
      if end < sentence[0].start - 0.125:
        subtitles.append(Subtitle(start, end, subtitle_words))
        subtitle_words = []
        subtitle_char_count = 0

    for word in sentence:
      if subtitle_char_count + len(word.word) > 80:
        subtitles.append(Subtitle(subtitle_words[0].start, word.start, subtitle_words))
        subtitle_words = []
        subtitle_char_count = 0

      subtitle_words.append(word)
      subtitle_char_count += len(word.word)
    # TODO: Skip subtitles/sentences/phrases with low average probability
  
  if len(subtitle_words) > 0:
    start = subtitle_words[0].start
    end = max(start + 1.5, subtitle_words[-1].end)
    subtitles.append(Subtitle(start, end, subtitle_words))

  return subtitles

def _group_sentences(words: list[Word]) -> list[list[Word]]:
  """Groups words from a list into sentences based on punctuation."""
  sentences = []
  current_sentence = []
  for word in words:
    current_sentence.append(word)
    text = word.word
    if text.endswith('.') or text.endswith('!') or text.endswith('?'):
      sentences.append(current_sentence)
      current_sentence = []
  if len(current_sentence) > 0:
    sentences.append(current_sentence)
  return sentences

FILE_HEADER = \
"""[Script Info]
; Script generated by automute
ScriptType: v4.00+
PlayResX: 480
PlayResY: 360
ScaledBorderAndShadow: yes

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,18,&Hffffff,&H00ffff,&H000000,&H80000000,0,0,0,0,100,100,0,0,1,1,1,2,10,10,10,0

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
LINE_FORMAT = "Dialogue: 0,{start},{end},Default,,0,0,0,,{text}\n"
WORD_FORMAT = "{{\\1a&H{alpha:02X}&}}{text}{{\\1a}}"

# SRT does not seem to support font opacity, only color.
# mov_text (i.e., mp4) does not seem to support font color at all.
# Only SubStation Alpha seems to support opacity.
# It seems like ffmpeg likes to have all of the possible fields present, at least when converting from SSA to SRT.
def create_subtitles_script(subtitles: list[Subtitle]) -> str:
  contents = [FILE_HEADER]
  for subtitle in subtitles:
    start = _seconds_to_ts(subtitle.start)
    end = _seconds_to_ts(subtitle.end)
    text = ""
    first = True
    for word in subtitle.words:
      word_text = word.word
      if first:
        word_text = word_text.lstrip()
        first = False
      text += WORD_FORMAT.format(alpha=_probability_to_alpha(word.probability), text=word_text)
    contents.append(LINE_FORMAT.format(start=start, end=end, text=text.strip()))
  return ''.join(contents)

def _seconds_to_ts(seconds: float) -> str:
  centiseconds = round(seconds * 100)
  seconds = centiseconds // 100
  minutes = seconds // 60
  hours = minutes // 60
  centiseconds %= 100
  seconds %= 60
  minutes %= 60
  return f"{hours:01}:{minutes:02}:{seconds:02}.{centiseconds:02}"

def _probability_to_alpha(probability: float) -> int:
  MIN_ALPHA = 0x00
  MAX_ALPHA = 0xA0
  MIN_PROBABILITY = 0.2
  MAX_PROBABILITY = 0.9
  lerp = 1.0 - min(max((probability - MIN_PROBABILITY) / (MAX_PROBABILITY - MIN_PROBABILITY), 0.0), 1.0)
  return MIN_ALPHA + int(lerp * (MAX_ALPHA - MIN_ALPHA))

def add_subtitles_to_video(video_file: str, subtitles_script: str, output_file: str):
  if os.path.isfile(output_file):
    # TODO: Confirm before continuing
    os.remove(output_file)
  av = ffmpeg.input(video_file)
  subtitles = ffmpeg.input('pipe:')
  stream = ffmpeg.output(av, subtitles, output_file, c="copy", loglevel="error")
  process = ffmpeg.run_async(stream, pipe_stdin=True)
  process.stdin.write(subtitles_script.encode())
  process.stdin.close()
  if process.wait() != 0:
    print("Error from ffmpeg")

def _get_filtered_video_path(input_file: str) -> str:
  """Creates an output file path from an input file path."""
  input_path = pathlib.Path(input_file)
  return str(input_path.with_stem(input_path.stem + "-filtered"))

def _get_output_file_path(input_file: str) -> str:
  """Creates an output file path from an input file path."""
  input_path = pathlib.Path(input_file)
  return str(input_path.with_stem(input_path.stem + "-subtitled").with_suffix(".mkv"))

def main():
  filter_list = compile_filters([], ['default_wordlist_en.txt'])

  video_file = "./media/missile.mp4"
  segments = transcribe(video_file, TranscribeOptions(model="large-v3"))
  segments, matches = filter_transcription(segments, filter_list, '[__]', True)
  print(f"Found {matches} matches for filters")
  subtitles = layout_subtitles(segments)
  script = create_subtitles_script(subtitles)

  output_file = _get_output_file_path(video_file)
  add_subtitles_to_video(_get_filtered_video_path(video_file), script, output_file)
  print("Added subtitles to video")

  # TODO: https://www.bannerbear.com/blog/how-to-add-subtitles-to-a-video-file-using-ffmpeg/#hard-subtitles-vs-soft-subtitles

if __name__ == "__main__":
  main()
